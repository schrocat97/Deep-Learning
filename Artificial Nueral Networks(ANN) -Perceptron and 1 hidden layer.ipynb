{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "722eccaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\aditya\\anaconda3\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (23.1.21)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (15.0.6.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.6)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.2)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.5)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.30.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.51.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.16.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f38e9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\aditya\\anaconda3\\lib\\site-packages (2.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3160fc29",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18840\\1349810148.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models, layers, utils, backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a4a1b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shap\n",
      "  Downloading shap-0.41.0-cp39-cp39-win_amd64.whl (435 kB)\n",
      "     ------------------------------------- 435.6/435.6 kB 40.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm>4.25.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from shap) (4.64.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from shap) (1.4.4)\n",
      "Requirement already satisfied: numba in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from shap) (0.55.1)\n",
      "Collecting slicer==0.0.7\n",
      "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from shap) (21.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from shap) (1.21.5)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from shap) (2.0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from shap) (1.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from shap) (1.9.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from packaging>20.9->shap) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tqdm>4.25.0->shap) (0.4.5)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from numba->shap) (0.38.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from numba->shap) (63.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from pandas->shap) (2022.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from scikit-learn->shap) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from scikit-learn->shap) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n",
      "Installing collected packages: slicer, shap\n",
      "Successfully installed shap-0.41.0 slicer-0.0.7\n"
     ]
    }
   ],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dc76c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f240cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 7s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train,y_train) , (x_test,y_test) = keras.datasets.mnist.load_data() # Loading the hand-written digits Dataset from the Keras library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d51ea577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b914224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c00e2ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d623ce20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5623063b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b07c38b070>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to visualize a particular number in the Dataset we can use matplotlibs matshow and visualize the particular number from the\n",
    "#x-Train dataset\n",
    "plt.matshow(x_train[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4abb3c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48587917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9], dtype=uint8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6fdec7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape # we want to reshape this into (60000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8d07e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f929932",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "05cc51ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will have to flatten the 28 x 28 matrix into a single dimensional array like 1 column and 784 rows\n",
    "# for that we will be using the pandas function reshape and input the required shape\n",
    "x_train_flat = x_train.reshape(len(x_train),28*28) # length of the x_train is 60000 and the no. of rows is 784 so we have changed the shape from 28 X 28 to 784 x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cab4f0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "954ce9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarly we have to reshape the test dataset as well\n",
    "x_test_flat = x_test.reshape(len(x_test),28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "32be76bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c94ac481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "       0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117647, 0.36862745, 0.60392157,\n",
       "       0.66666667, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235294, 0.6745098 , 0.99215686, 0.94901961,\n",
       "       0.76470588, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215686, 0.93333333,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.98431373, 0.36470588,\n",
       "       0.32156863, 0.32156863, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882353, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.71372549,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31372549, 0.61176471, 0.41960784, 0.99215686, 0.99215686,\n",
       "       0.80392157, 0.04313725, 0.        , 0.16862745, 0.60392157,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509804,\n",
       "       0.99215686, 0.74509804, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313725, 0.74509804, 0.99215686,\n",
       "       0.2745098 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.1372549 , 0.94509804, 0.88235294, 0.62745098,\n",
       "       0.42352941, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764706, 0.94117647, 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "       0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.36470588,\n",
       "       0.98823529, 0.99215686, 0.73333333, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.97647059, 0.99215686,\n",
       "       0.97647059, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980392,\n",
       "       0.71764706, 0.99215686, 0.99215686, 0.81176471, 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.58039216, 0.89803922, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.71372549, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882353, 0.83529412, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.31764706,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058824, 0.85882353,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.76470588,\n",
       "       0.31372549, 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568627, 0.6745098 ,\n",
       "       0.88627451, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156863, 0.04313725, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333333, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137255, 0.52941176, 0.51764706, 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_flat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4dbf54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will create the simple nueral network\n",
    "# It is a perceptron ,i.e., a single input layer with 784 layers and an output layer that has 10 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4065657e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 796us/step - loss: 0.4684 - accuracy: 0.8780\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 762us/step - loss: 0.3042 - accuracy: 0.9152\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 784us/step - loss: 0.2833 - accuracy: 0.9204\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 762us/step - loss: 0.2733 - accuracy: 0.9247\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 771us/step - loss: 0.2669 - accuracy: 0.9257\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 770us/step - loss: 0.2620 - accuracy: 0.9273\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 771us/step - loss: 0.2584 - accuracy: 0.9288\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 766us/step - loss: 0.2562 - accuracy: 0.9291\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1s 773us/step - loss: 0.2526 - accuracy: 0.9301\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 810us/step - loss: 0.2511 - accuracy: 0.9303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b07d94caf0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we will be using the Sequential NN in Keras\n",
    "# optimizer means the algo to get to the local minima and here the loss sparse_categorical_crossentropy is used.\n",
    "# categorical means that our output variable y_train is an integer and sparse because if the array was hot encoded then we would have used only\n",
    "# categorical_crossentropy\n",
    "# the metrics that we will be computing is accuracy of the NN built and so it the metrics 'accuracy' is added\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(10, input_shape=(784,),activation = 'sigmoid')\n",
    "])\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "# Now the model will be trained and so the .fit() is used here.\n",
    "model.fit(x_train_flat, y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3877b685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The accuracy is not very good, so to make the model more accurate the epochs could be increased but that would take a lot of epochs\n",
    "# to make the accuracy higher, we can make the data scaled\n",
    "# This is done to get all the values scaled and that can be done in this case by dividing all the values in the \n",
    "# x_train and x_test datasets by 255 since that is the maximum value \n",
    "# now we can see that the accuracy has increased and the accuracy is a lot better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2d5debf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4341fc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 810us/step - loss: 0.2652 - accuracy: 0.9257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26524171233177185, 0.9257000088691711]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we have to evaluate the accuracy of the model on the test dataset:\n",
    "\n",
    "model.evaluate(x_test_flat,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "440489a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seems to have a pretty decent accuracy as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "486a2277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b07ad06340>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_test[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ed2bd39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 526us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.58871222e-01, 6.32754900e-03, 9.99696970e-01, 1.24268331e-01,\n",
       "       1.77198724e-11, 8.85571539e-01, 9.38440561e-01, 3.08497912e-15,\n",
       "       1.01153076e-01, 5.12645482e-12], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model.predict(x_test_flat)\n",
    "y_predict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3f5357d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will print this values using the argmax func in numpy this prints the index of the maximum value in the array\n",
    "np.argmax(y_predict[5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "97e1e371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 2, 1, 0, 4]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will be making a confusion matrix between y_test and y_predicted to check the accuracy\n",
    "# But y_predict are all real values and y_test are integers\n",
    "# We will be doing this by actually calculating the argmax values/\"labels\" for each of the value in the y_predict\n",
    "# This is called list comprehension\n",
    "# We can create a new list form an existing list by using a for loop in it and storing the labels in a new variable, this we will \n",
    "# use for computing our confusion matrix\n",
    "y_predict_labels = [np.argmax(i) for i in y_predict]\n",
    "y_predict_labels[:5] # printing the first 5 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cf45d481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4], dtype=uint8)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5e4ff2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that the values in the y_predict and the y_test matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "10d1bce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a5e260d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
       "array([[ 957,    0,    1,    2,    0,    8,    8,    3,    1,    0],\n",
       "       [   0, 1113,    3,    2,    0,    1,    4,    2,   10,    0],\n",
       "       [   6,   11,  908,   19,    8,    7,   12,   13,   45,    3],\n",
       "       [   3,    0,   11,  918,    0,   34,    3,   12,   22,    7],\n",
       "       [   1,    1,    5,    2,  914,    0,    9,    5,    9,   36],\n",
       "       [   8,    2,    1,   23,    7,  797,   12,    7,   29,    6],\n",
       "       [  10,    3,    7,    1,    7,   14,  912,    2,    2,    0],\n",
       "       [   1,    8,   18,    5,    6,    1,    0,  953,    3,   33],\n",
       "       [   5,   10,    5,   19,    9,   32,   10,   10,  864,   10],\n",
       "       [  10,    8,    1,    8,   20,    8,    0,   27,    6,  921]])>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = tf.math.confusion_matrix(labels = y_test, predictions = y_predict_labels)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e059ce13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2105 - accuracy: 0.9377\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0852 - accuracy: 0.9737\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0550 - accuracy: 0.9828\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0391 - accuracy: 0.9877\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0276 - accuracy: 0.9913\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0221 - accuracy: 0.9930\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0183 - accuracy: 0.9941\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0140 - accuracy: 0.9955\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0133 - accuracy: 0.9959\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0087 - accuracy: 0.9972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b0266fa7f0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will be adding a hidden layer to our previous NN:\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(393, input_shape=(784,),activation = 'relu'),\n",
    "    keras.layers.Dense(10,activation = 'sigmoid')\n",
    "])\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "# Now the model will be trained and so the .fit() is used here.\n",
    "model.fit(x_train_flat, y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "32823dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that the accuracy has increased to more than 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fe4ded9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b026969190>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_test[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "22492880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7.7629309e-08, 8.2335472e-01, 1.0000000e+00, 4.4335284e-05,\n",
       "       1.8109500e-14, 1.2799131e-06, 2.4668903e-05, 1.8796247e-13,\n",
       "       4.6517025e-06, 4.1049941e-12], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model.predict(x_test_flat)\n",
    "y_predict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fafae929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will print this values using the argmax func in numpy this prints the index of the maximum value in the array\n",
    "np.argmax(y_predict[5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1063e8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 2, 1, 0, 4]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will be making a confusion matrix between y_test and y_predicted to check the accuracy\n",
    "# But y_predict are all real values and y_test are integers\n",
    "# We will be doing this by actually calculating the argmax values/\"labels\" for each of the value in the y_predict\n",
    "# This is called list comprehension\n",
    "# We can create a new list form an existing list by using a for loop in it and storing the labels in a new variable, this we will \n",
    "# use for computing our confusion matrix\n",
    "y_predict_labels = [np.argmax(i) for i in y_predict]\n",
    "y_predict_labels[:5] # printing the first 5 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1957377f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4], dtype=uint8)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f4dc8409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
       "array([[ 974,    0,    1,    1,    1,    0,    1,    1,    1,    0],\n",
       "       [   1, 1123,    3,    3,    1,    0,    2,    0,    2,    0],\n",
       "       [   1,    0, 1010,    5,    6,    0,    0,    6,    4,    0],\n",
       "       [   0,    0,    3,  993,    0,    4,    0,    1,    2,    7],\n",
       "       [   1,    1,    4,    0,  972,    0,    1,    0,    0,    3],\n",
       "       [   2,    0,    0,    9,    1,  870,    2,    0,    4,    4],\n",
       "       [   1,    3,    0,    1,    8,    2,  943,    0,    0,    0],\n",
       "       [   0,    3,    7,    2,    6,    0,    0,  999,    2,    9],\n",
       "       [   1,    0,    1,    5,    3,    1,    4,    2,  951,    6],\n",
       "       [   0,    2,    0,    2,   29,    4,    1,    3,    2,  966]])>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = tf.math.confusion_matrix(labels = y_test, predictions = y_predict_labels)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fa9d012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can see that the error have gone down a lot more in the cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b3b607e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0839 - accuracy: 0.9801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08391229808330536, 0.9800999760627747]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_flat,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d4aa58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
